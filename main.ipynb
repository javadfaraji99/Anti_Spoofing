{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_random_frames(video_path, num_frames=100):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    if total_frames < num_frames:\n",
    "        raise ValueError(f\"The video {video_path} doesn't have enough frames.\")\n",
    "    \n",
    "    frame_indices = random.sample(range(total_frames), num_frames)\n",
    "    frames = []\n",
    "\n",
    "    for frame_idx in sorted(frame_indices):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        if ret:\n",
    "            frames.append(frame)\n",
    "        else:\n",
    "            print(f\"Failed to read frame at index {frame_idx} in video {video_path}\")\n",
    "    \n",
    "    cap.release()\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frame(model, frame):\n",
    "    # Preprocess the frame if necessary (e.g., resizing, normalization)\n",
    "    processed_frame = cv2.resize(frame, (model.input_shape[1], model.input_shape[2]))\n",
    "    processed_frame = processed_frame / 255.0\n",
    "    processed_frame = np.expand_dims(processed_frame, axis=0)\n",
    "    \n",
    "    # Predict the class (0 or 1)\n",
    "    prediction = model.predict(processed_frame)\n",
    "    return np.argmax(prediction, axis=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(video_path, models):\n",
    "    frames = extract_random_frames(video_path, num_frames=100)\n",
    "    predictions = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "    for frame in frames:\n",
    "        for model_name, model in models.items():\n",
    "            prediction = predict_frame(model, frame)\n",
    "            predictions[model_name].append(prediction)\n",
    "    \n",
    "    average_predictions = {model_name: np.mean(preds) for model_name, preds in predictions.items()}\n",
    "    return average_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(dataset_path, model_paths, output_csv):\n",
    "    models = {model_name: load_model(model_path) for model_name, model_path in model_paths.items()}\n",
    "    \n",
    "    # Read video paths from dataset.txt\n",
    "    with open(dataset_path, 'r') as file:\n",
    "        videos = [line.strip() for line in file.readlines()]\n",
    "\n",
    "    with open(output_csv, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        header = ['Video'] + list(models.keys())\n",
    "        writer.writerow(header)\n",
    "\n",
    "        for video in videos:\n",
    "            if not os.path.exists(video):\n",
    "                print(f\"Video file {video} does not exist. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            average_predictions = process_video(video, models)\n",
    "            row = [os.path.basename(video)] + [average_predictions[model_name] for model_name in models.keys()]\n",
    "            writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'dataset.txt'\n",
    "model_paths = {\n",
    "    'model1': 'path_to_model1.h5',\n",
    "    'model2': 'path_to_model2.h5',\n",
    "    'model3': 'path_to_model3.h5'\n",
    "}\n",
    "output_csv = 'predictions.csv'\n",
    "\n",
    "main(dataset_path, model_paths, output_csv)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
